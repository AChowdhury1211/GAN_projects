{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(3, 32, 32), nrow=5, show=True):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan=3, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4, kernel_size=4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim, kernel_size=4),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=2, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, input_dim, device=device)\n",
    "\n",
    "def combine_vectors(x, y):\n",
    "    return torch.cat([x, y], 1)\n",
    "\n",
    "def get_one_hot_labels(labels, n_classes):\n",
    "    return F.one_hot(labels, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_shape = (3, 32, 32)\n",
    "n_classes = 100\n",
    "n_epochs = 10000\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "device = 'cuda'\n",
    "generator_input_dim = z_dim + n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, im_chan, n_classes, hidden_dim=32):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_classifier_block(im_chan, hidden_dim),\n",
    "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_classifier_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            self.make_classifier_block(hidden_dim * 4, n_classes, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_classifier_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        class_pred = self.disc(image)\n",
    "        return class_pred.view(len(class_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=3, hidden_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim, stride=1),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            self.make_disc_block(hidden_dim * 4, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)\n",
    "\n",
    "def train_generator():\n",
    "    gen = Generator(generator_input_dim).to(device)\n",
    "    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "    discriminator_input_dim = cifar100_shape[0] + n_classes\n",
    "    disc = Discriminator(discriminator_input_dim).to(device)\n",
    "    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    gen = gen.apply(weights_init)\n",
    "    disc = disc.apply(weights_init)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    cur_step = 0\n",
    "    mean_generator_loss = 0\n",
    "    mean_discriminator_loss = 0\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        for real, labels in dataloader:\n",
    "            cur_batch_size = len(real)\n",
    "\n",
    "            real = real.to(device)\n",
    "\n",
    "            one_hot_labels = get_one_hot_labels(labels.to(device), n_classes).float()\n",
    "\n",
    "            image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "            image_one_hot_labels = image_one_hot_labels.repeat(1, 1, cifar100_shape[1], cifar100_shape[2])\n",
    "            disc_opt.zero_grad()\n",
    "\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "\n",
    "            noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "            fake = gen(noise_and_labels)\n",
    "\n",
    "            fake_image_and_labels = combine_vectors(fake.detach(), image_one_hot_labels)\n",
    "            real_image_and_labels = combine_vectors(real, image_one_hot_labels)\n",
    "            disc_fake_pred = disc(fake_image_and_labels)\n",
    "            disc_real_pred = disc(real_image_and_labels)\n",
    "\n",
    "            disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "            disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "            disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_opt.step() \n",
    "\n",
    "\n",
    "            mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "            gen_opt.zero_grad()\n",
    "\n",
    "\n",
    "            fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n",
    "\n",
    "            disc_fake_pred = disc(fake_image_and_labels)\n",
    "            gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "\n",
    "            mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "                show_tensor_images(fake)\n",
    "                show_tensor_images(real)\n",
    "                mean_generator_loss = 0\n",
    "                mean_discriminator_loss = 0\n",
    "            cur_step += 1\n",
    "\n",
    "def train_classifier():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    n_epochs = 10\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        CIFAR100(\".\", train=False, download=True, transform=transform),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    display_step = 10\n",
    "    batch_size = 512\n",
    "    lr = 0.0002\n",
    "    device = 'cuda'\n",
    "    classifier = Classifier(cifar100_shape[0], n_classes).to(device)\n",
    "    classifier_opt = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "    cur_step = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for real, labels in tqdm(dataloader):\n",
    "            cur_batch_size = len(real)\n",
    "            real = real.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            classifier_opt.zero_grad()\n",
    "            labels_hat = classifier(real.detach())\n",
    "            classifier_loss = criterion(labels_hat, labels)\n",
    "            classifier_loss.backward()\n",
    "            classifier_opt.step()\n",
    "\n",
    "            if cur_step % display_step == 0:\n",
    "                classifier_val_loss = 0\n",
    "                classifier_correct = 0\n",
    "                num_validation = 0\n",
    "                for val_example, val_label in validation_dataloader:\n",
    "                    cur_batch_size = len(val_example)\n",
    "                    num_validation += cur_batch_size\n",
    "                    val_example = val_example.to(device)\n",
    "                    val_label = val_label.to(device)\n",
    "                    labels_hat = classifier(val_example)\n",
    "                    classifier_val_loss += criterion(labels_hat, val_label) * cur_batch_size\n",
    "                    classifier_correct += (labels_hat.argmax(1) == val_label).float().sum()\n",
    "\n",
    "                print(f\"Step {cur_step}: \"\n",
    "                        f\"Classifier loss: {classifier_val_loss.item() / num_validation}, \"\n",
    "                        f\"classifier accuracy: {classifier_correct.item() / num_validation}\")\n",
    "            cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sample(real, fake, p_real):\n",
    "    make_fake = torch.rand(len(real)) > p_real\n",
    "    target_images = real.clone()\n",
    "    target_images[make_fake] = fake[make_fake]\n",
    "    return target_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = 9999\n",
    "test_combination = combine_sample(\n",
    "    torch.ones(n_test_samples, 1), \n",
    "    torch.zeros(n_test_samples, 1), \n",
    "    0.3\n",
    ")\n",
    "\n",
    "assert tuple(test_combination.shape) == (n_test_samples, 1)\n",
    "\n",
    "assert torch.abs(test_combination.mean() - 0.3) < 0.05\n",
    "\n",
    "assert test_combination.median() < 1e-5\n",
    "\n",
    "test_combination = combine_sample(\n",
    "    torch.ones(n_test_samples, 10, 10), \n",
    "    torch.zeros(n_test_samples, 10, 10), \n",
    "    0.8\n",
    ")\n",
    "\n",
    "assert tuple(test_combination.shape) == (n_test_samples, 10, 10)\n",
    "\n",
    "assert torch.abs((test_combination.sum([1, 2]).median()) - 100) < 1e-5\n",
    "\n",
    "test_reals = torch.arange(n_test_samples)[:, None].float()\n",
    "test_fakes = torch.zeros(n_test_samples, 1)\n",
    "test_saved = (test_reals.clone(), test_fakes.clone())\n",
    "test_combination = combine_sample(test_reals, test_fakes, 0.3)\n",
    "\n",
    "assert torch.abs((test_combination.mean() - 1500)) < 100\n",
    "\n",
    "assert torch.abs(test_saved[0] - test_reals).sum() < 1e-3\n",
    "assert torch.abs(test_saved[1] - test_fakes).sum() < 1e-3\n",
    "\n",
    "test_fakes = torch.arange(n_test_samples)[:, None].float()\n",
    "test_combination = combine_sample(test_reals, test_fakes, 0.3)\n",
    "\n",
    "assert torch.abs(test_combination - test_reals).sum() < 1e-4\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal():\n",
    "    gen_names = [\n",
    "        \"gen_1.pt\",\n",
    "        \"gen_2.pt\",\n",
    "        \"gen_3.pt\",\n",
    "        \"gen_4.pt\"\n",
    "    ]\n",
    "\n",
    "    best_p_real, best_gen_name = 0.6, \"gen_4.pt\"\n",
    "\n",
    "    return best_p_real, best_gen_name\n",
    "\n",
    "def augmented_train(p_real, gen_name):\n",
    "    gen = Generator(generator_input_dim).to(device)\n",
    "    gen.load_state_dict(torch.load(gen_name))\n",
    "\n",
    "    classifier = Classifier(cifar100_shape[0], n_classes).to(device)\n",
    "    classifier.load_state_dict(torch.load(\"class.pt\"))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size = 256\n",
    "\n",
    "    train_set = torch.load(\"insect_train.pt\")\n",
    "    val_set = torch.load(\"insect_val.pt\")\n",
    "    dataloader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(train_set[\"images\"], train_set[\"labels\"]),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    validation_dataloader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(val_set[\"images\"], val_set[\"labels\"]),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    display_step = 1\n",
    "    lr = 0.0002\n",
    "    n_epochs = 20\n",
    "    classifier_opt = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "    cur_step = 0\n",
    "    best_score = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for real, labels in dataloader:\n",
    "            real = real.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            one_hot_labels = get_one_hot_labels(labels.to(device), n_classes).float()\n",
    "\n",
    "            classifier_opt.zero_grad()\n",
    "            cur_batch_size = len(labels)\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "            fake = gen(noise_and_labels)\n",
    "\n",
    "            target_images = combine_sample(real.clone(), fake.clone(), p_real)\n",
    "            labels_hat = classifier(target_images.detach())\n",
    "            classifier_loss = criterion(labels_hat, labels)\n",
    "            classifier_loss.backward()\n",
    "            classifier_opt.step()\n",
    "\n",
    "\n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                classifier_val_loss = 0\n",
    "                classifier_correct = 0\n",
    "                num_validation = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_example, val_label in validation_dataloader:\n",
    "                        cur_batch_size = len(val_example)\n",
    "                        num_validation += cur_batch_size\n",
    "                        val_example = val_example.to(device)\n",
    "                        val_label = val_label.to(device)\n",
    "                        labels_hat = classifier(val_example)\n",
    "                        classifier_val_loss += criterion(labels_hat, val_label) * cur_batch_size\n",
    "                        classifier_correct += (labels_hat.argmax(1) == val_label).float().sum()\n",
    "                    accuracy = classifier_correct.item() / num_validation\n",
    "                    if accuracy > best_score:\n",
    "                        best_score = accuracy\n",
    "            cur_step += 1\n",
    "    return best_score\n",
    "\n",
    "def eval_augmentation(p_real, gen_name, n_test=20):\n",
    "    total = 0\n",
    "    for i in range(n_test):\n",
    "        total += augmented_train(p_real, gen_name)\n",
    "    return total / n_test\n",
    "\n",
    "best_p_real, best_gen_name = find_optimal()\n",
    "performance = eval_augmentation(best_p_real, best_gen_name)\n",
    "print(f\"Your model had an accuracy of {performance:0.1%}\")\n",
    "assert performance > 0.51\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [4, 41, 80, 122, 160]\n",
    "train_images = torch.load(\"insect_train.pt\")[\"images\"][examples]\n",
    "train_labels = torch.load(\"insect_train.pt\")[\"labels\"][examples]\n",
    "\n",
    "one_hot_labels = get_one_hot_labels(train_labels.to(device), n_classes).float()\n",
    "fake_noise = get_noise(len(train_images), z_dim, device=device)\n",
    "noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "gen = Generator(generator_input_dim).to(device)\n",
    "gen.load_state_dict(torch.load(best_gen_name))\n",
    "\n",
    "fake = gen(noise_and_labels)\n",
    "show_tensor_images(torch.cat([train_images.cpu(), fake.cpu()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
