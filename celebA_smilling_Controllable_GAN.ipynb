{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import CelebA\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 8),\n",
    "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, im_chan=3, n_classes=2, hidden_dim=64):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.make_classifier_block(im_chan, hidden_dim),\n",
    "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_classifier_block(hidden_dim * 2, hidden_dim * 4, stride=3),\n",
    "            self.make_classifier_block(hidden_dim * 4, n_classes, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_classifier_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        class_pred = self.classifier(image)\n",
    "        return class_pred.view(len(class_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 64\n",
    "batch_size = 128\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(filename):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    label_indices = range(40)\n",
    "\n",
    "    n_epochs = 3\n",
    "    display_step = 500\n",
    "    lr = 0.001\n",
    "    beta_1 = 0.5\n",
    "    beta_2 = 0.999\n",
    "    image_size = 64\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        CelebA(\".\", split='train', download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    classifier = Classifier(n_classes=len(label_indices)).to(device)\n",
    "    class_opt = torch.optim.Adam(classifier.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    cur_step = 0\n",
    "    classifier_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for real, labels in tqdm(dataloader):\n",
    "            real = real.to(device)\n",
    "            labels = labels[:, label_indices].to(device).float()\n",
    "\n",
    "            class_opt.zero_grad()\n",
    "            class_pred = classifier(real)\n",
    "            class_loss = criterion(class_pred, labels)\n",
    "            class_loss.backward()\n",
    "            class_opt.step() \n",
    "            classifier_losses += [class_loss.item()]\n",
    "\n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                class_mean = sum(classifier_losses[-display_step:]) / display_step\n",
    "                print(f\"Step {cur_step}: Classifier loss: {class_mean}\")\n",
    "                step_bins = 20\n",
    "                x_axis = sorted([i * step_bins for i in range(len(classifier_losses) // step_bins)] * step_bins)\n",
    "                sns.lineplot(x_axis, classifier_losses[:len(x_axis)], label=\"Classifier Loss\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                torch.save({\"classifier\": classifier.state_dict()}, filename)\n",
    "            cur_step += 1\n",
    "# train_classifier(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_dict = torch.load(\"pretrained_celeba.pth\", map_location=torch.device(device))[\"gen\"]\n",
    "gen.load_state_dict(gen_dict)\n",
    "gen.eval()\n",
    "\n",
    "n_classes = 40\n",
    "classifier = Classifier(n_classes=n_classes).to(device)\n",
    "class_dict = torch.load(\"pretrained_classifier.pth\", map_location=torch.device(device))[\"classifier\"]\n",
    "classifier.load_state_dict(class_dict)\n",
    "classifier.eval()\n",
    "print(\"Loaded the models!\")\n",
    "\n",
    "opt = torch.optim.Adam(classifier.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_updated_noise(noise, weight):\n",
    "    new_noise = noise + noise.grad * weight\n",
    "    return new_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "noise = torch.ones(20, 20) * 2\n",
    "noise.requires_grad_()\n",
    "fake_classes = (noise ** 2).mean()\n",
    "fake_classes.backward()\n",
    "new_noise = calculate_updated_noise(noise, 0.1)\n",
    "assert type(new_noise) == torch.Tensor\n",
    "assert tuple(new_noise.shape) == (20, 20)\n",
    "assert new_noise.max() == 2.0010\n",
    "assert new_noise.min() == 2.0010\n",
    "assert torch.isclose(new_noise.sum(), torch.tensor(0.4) + 20 * 20 * 2)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "noise = get_noise(32, z_dim).to(device).requires_grad_()\n",
    "fake = gen(noise)\n",
    "fake_classes = classifier(fake)[:, 0]\n",
    "fake_classes.mean().backward()\n",
    "noise.data = calculate_updated_noise(noise, 0.01)\n",
    "fake = gen(noise)\n",
    "fake_classes_new = classifier(fake)[:, 0]\n",
    "assert torch.all(fake_classes_new > fake_classes)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 8\n",
    "fake_image_history = []\n",
    "grad_steps = 10 \n",
    "skip = 2\n",
    "\n",
    "feature_names = [\"5oClockShadow\", \"ArchedEyebrows\", \"Attractive\", \"BagsUnderEyes\", \"Bald\", \"Bangs\",\n",
    "\"BigLips\", \"BigNose\", \"BlackHair\", \"BlondHair\", \"Blurry\", \"BrownHair\", \"BushyEyebrows\", \"Chubby\",\n",
    "\"DoubleChin\", \"Eyeglasses\", \"Goatee\", \"GrayHair\", \"HeavyMakeup\", \"HighCheekbones\", \"Male\", \n",
    "\"MouthSlightlyOpen\", \"Mustache\", \"NarrowEyes\", \"NoBeard\", \"OvalFace\", \"PaleSkin\", \"PointyNose\", \n",
    "\"RecedingHairline\", \"RosyCheeks\", \"Sideburn\", \"Smiling\", \"StraightHair\", \"WavyHair\", \"WearingEarrings\", \n",
    "\"WearingHat\", \"WearingLipstick\", \"WearingNecklace\", \"WearingNecktie\", \"Young\"]\n",
    "\n",
    "\n",
    "target_indices = feature_names.index(\"Smiling\") \n",
    "\n",
    "noise = get_noise(n_images, z_dim).to(device).requires_grad_()\n",
    "for i in range(grad_steps):\n",
    "    opt.zero_grad()\n",
    "    fake = gen(noise)\n",
    "    fake_image_history += [fake]\n",
    "    fake_classes_score = classifier(fake)[:, target_indices].mean()\n",
    "    fake_classes_score.backward()\n",
    "    noise.data = calculate_updated_noise(noise, 1 / grad_steps)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [n_images * 2, grad_steps * 2]\n",
    "show_tensor_images(torch.cat(fake_image_history[::skip], dim=2), num_images=n_images, nrow=n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(current_classifications, original_classifications, target_indices, other_indices, penalty_weight):\n",
    "t\n",
    "    other_distances = current_classifications[:, other_indices] - original_classifications[:, other_indices]\n",
    "\n",
    "    other_class_penalty = -torch.norm(other_distances, dim=1).mean() * penalty_weight\n",
    "\n",
    "    target_score = current_classifications[:, target_indices].mean()\n",
    "\n",
    "    return target_score + other_class_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isclose(\n",
    "    get_score(torch.ones(4, 3), torch.zeros(4, 3), [0], [1, 2], 0.2), \n",
    "    1 - torch.sqrt(torch.tensor(2.)) * 0.2\n",
    ")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_history = []\n",
    "\n",
    "target_indices = feature_names.index(\"Smiling\") \n",
    "other_indices = [cur_idx != target_indices for cur_idx, _ in enumerate(feature_names)]\n",
    "noise = get_noise(n_images, z_dim).to(device).requires_grad_()\n",
    "original_classifications = classifier(gen(noise)).detach()\n",
    "for i in range(grad_steps):\n",
    "    opt.zero_grad()\n",
    "    fake = gen(noise)\n",
    "    fake_image_history += [fake]\n",
    "    fake_score = get_score(\n",
    "        classifier(fake), \n",
    "        original_classifications,\n",
    "        target_indices,\n",
    "        other_indices,\n",
    "        penalty_weight=0.1\n",
    "    )\n",
    "    fake_score.backward()\n",
    "    noise.data = calculate_updated_noise(noise, 1 / grad_steps)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [n_images * 2, grad_steps * 2]\n",
    "show_tensor_images(torch.cat(fake_image_history[::skip], dim=2), num_images=n_images, nrow=n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
