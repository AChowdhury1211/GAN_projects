{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 8),\n",
    "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 64\n",
    "image_size = 299\n",
    "device = 'cpu' \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "in_coursera = True \n",
    "if in_coursera:\n",
    "    import numpy as np\n",
    "    data = torch.Tensor(np.load('fid_images_tensor.npz', allow_pickle=True)['arr_0'])\n",
    "    dataset = torch.utils.data.TensorDataset(data, data)\n",
    "else:\n",
    "    dataset = CelebA(\".\", download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen.load_state_dict(torch.load(f\"pretrained_celeba.pth\", map_location=torch.device(device))[\"gen\"])\n",
    "gen = gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "inception_model = inception_v3(pretrained=False)\n",
    "inception_model.load_state_dict(torch.load(\"inception_v3_google-1a9a5a14.pth\"))\n",
    "inception_model.to(device)\n",
    "inception_model = inception_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity_noise = torch.randn(100, 100)\n",
    "assert torch.equal(test_identity_noise, inception_model.fc(test_identity_noise))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal\n",
    "import seaborn as sns \n",
    "mean = torch.Tensor([0, 0])\n",
    "covariance = torch.Tensor( \n",
    "    [[1, 0],\n",
    "     [0, 1]]\n",
    ")\n",
    "independent_dist = MultivariateNormal(mean, covariance)\n",
    "samples = independent_dist.sample((10000,))\n",
    "res = sns.jointplot(samples[:, 0], samples[:, 1], kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.Tensor([0, 0])\n",
    "covariance = torch.Tensor(\n",
    "    [[2, -1],\n",
    "     [-1, 2]]\n",
    ")\n",
    "covariant_dist = MultivariateNormal(mean, covariance)\n",
    "samples = covariant_dist.sample((10000,))\n",
    "res = sns.jointplot(samples[:, 0], samples[:, 1], kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def matrix_sqrt(x):\n",
    "    y = x.cpu().detach().numpy()\n",
    "    y = scipy.linalg.sqrtm(y)\n",
    "    return torch.Tensor(y.real, device=x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frechet_distance(mu_x, mu_y, sigma_x, sigma_y):\n",
    "    return (mu_x - mu_y).dot(mu_x - mu_y) + torch.trace(sigma_x) + torch.trace(sigma_y) - 2*torch.trace(matrix_sqrt(sigma_x @ sigma_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isclose(\n",
    "    frechet_distance(\n",
    "        independent_dist.mean, covariant_dist.mean,\n",
    "        independent_dist.covariance_matrix, covariant_dist.covariance_matrix\n",
    "    ),\n",
    "    4 - 2 * torch.sqrt(torch.tensor(3.))\n",
    ")\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = torch.nn.functional.interpolate(img, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_covariance(features):\n",
    "    return torch.Tensor(np.cov(features.detach().numpy(), rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_features_list = []\n",
    "real_features_list = []\n",
    "\n",
    "gen.eval()\n",
    "n_samples = 512 \n",
    "batch_size = 4 \n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "cur_samples = 0\n",
    "with torch.no_grad(): \n",
    "    try:\n",
    "        for real_example, _ in tqdm(dataloader, total=n_samples // batch_size):\n",
    "            real_samples = real_example\n",
    "            real_features = inception_model(real_samples.to(device)).detach().to('cpu') \n",
    "            real_features_list.append(real_features)\n",
    "\n",
    "            fake_samples = get_noise(len(real_example), z_dim).to(device)\n",
    "            fake_samples = preprocess(gen(fake_samples))\n",
    "            fake_features = inception_model(fake_samples.to(device)).detach().to('cpu')\n",
    "            fake_features_list.append(fake_features)\n",
    "            cur_samples += len(real_samples)\n",
    "            if cur_samples >= n_samples:\n",
    "                break\n",
    "    except:\n",
    "        print(\"Error in loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_features_all = torch.cat(fake_features_list)\n",
    "real_features_all = torch.cat(real_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_fake = fake_features_all.mean(0)\n",
    "mu_real = real_features_all.mean(0)\n",
    "sigma_fake = get_covariance(fake_features_all)\n",
    "sigma_real = get_covariance(real_features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tuple(sigma_fake.shape) == (fake_features_all.shape[1], fake_features_all.shape[1])\n",
    "assert tuple(sigma_real.shape) == (real_features_all.shape[1], real_features_all.shape[1])\n",
    "assert tuple(mu_fake.shape) == (fake_features_all.shape[1],)\n",
    "assert tuple(mu_real.shape) == (real_features_all.shape[1],)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz:\n",
    "indices = [2, 4, 5]\n",
    "fake_dist = MultivariateNormal(mu_fake[indices], sigma_fake[indices][:, indices])\n",
    "fake_samples = fake_dist.sample((5000,))\n",
    "real_dist = MultivariateNormal(mu_real[indices], sigma_real[indices][:, indices])\n",
    "real_samples = real_dist.sample((5000,))\n",
    "\n",
    "import pandas as pd\n",
    "df_fake = pd.DataFrame(fake_samples.numpy(), columns=indices)\n",
    "df_real = pd.DataFrame(real_samples.numpy(), columns=indices)\n",
    "df_fake[\"is_real\"] = \"no\"\n",
    "df_real[\"is_real\"] = \"yes\"\n",
    "df = pd.concat([df_fake, df_real])\n",
    "sns.pairplot(df, plot_kws={'alpha': 0.1}, hue='is_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(frechet_distance(mu_real, mu_fake, sigma_real, sigma_fake).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
